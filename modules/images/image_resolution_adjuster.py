# -*- coding: utf-8 -*-
# Filename: image_resolution_adjuster.py
# Developer: jammyfu
# Category: ğŸ¨PaintingğŸ‘“Coder/ğŸ–¼ï¸Image

import torch
import numpy as np
from PIL import Image
from math import gcd
import torch.nn.functional as F


def resize_image(image, target_width, target_height, method='contain', background_color='#000000'):
    """Resize an image while maintaining aspect ratio.
       method: 'contain', 'cover', 'fill', 'inside', 'outside'
    """
    # å°†ComfyUIçš„å›¾åƒTensorè½¬æ¢ä¸ºPILå›¾åƒå¯¹è±¡
    img = Image.fromarray(np.clip(255. * image.cpu().numpy(), 0, 255).astype(np.uint8))
    img_width, img_height = img.size

    if method == 'contain':
        # Contain: ç¼©æ”¾å›¾åƒä»¥é€‚åº”ç›®æ ‡å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”ï¼Œå¯èƒ½å‡ºç°èƒŒæ™¯
        img_ratio = img_width / img_height
        target_ratio = target_width / target_height
        if img_ratio > target_ratio:
            new_width = target_width
            new_height = int(target_width / img_ratio)
        else:
            new_height = target_height
            new_width = int(target_height * img_ratio)
        resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # è§£æèƒŒæ™¯é¢œè‰²
        try:
            color = tuple(int(background_color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
        except ValueError:
            color = (0, 0, 0)  # é»˜è®¤é»‘è‰²
            
        padded_img = Image.new('RGB', (target_width, target_height), color)
        x_offset = (target_width - new_width) // 2
        y_offset = (target_height - new_height) // 2
        padded_img.paste(resized_img, (x_offset, y_offset))
        
        # ç”Ÿæˆmask
        mask = calculate_mask((img_width, img_height), (target_width, target_height), method, scale_factor=1.0)
        return np.array(padded_img).astype(np.float32)/255.0, mask, target_width, target_height

    elif method == 'cover':
        # Cover: ç¼©æ”¾å›¾åƒä»¥è¦†ç›–ç›®æ ‡å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”ï¼Œå¯èƒ½è£å‰ª
        img_ratio = img_width / img_height
        target_ratio = target_width / target_height
        if img_ratio > target_ratio:
            new_height = target_height
            new_width = int(target_height * img_ratio)
        else:
            new_width = target_width
            new_height = int(target_width / img_ratio)
        resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        x_offset = (new_width - target_width) // 2
        y_offset = (new_height - target_height) // 2
        cropped_img = resized_img.crop((x_offset, y_offset, x_offset + target_width, y_offset + target_height))
        
        # ç”Ÿæˆmask
        mask = calculate_mask((img_width, img_height), (target_width, target_height), method, scale_factor=1.0)
        return np.array(cropped_img).astype(np.float32)/255.0, mask, target_width, target_height

    elif method == 'fill':
        # Fill: æ‹‰ä¼¸å›¾åƒä»¥å¡«å……ç›®æ ‡å°ºå¯¸ï¼Œå¿½ç•¥å®½é«˜æ¯”ï¼Œå¯èƒ½å˜å½¢
        resized_img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
        # ç”Ÿæˆmask
        mask = calculate_mask((img_width, img_height), (target_width, target_height), method, scale_factor=1.0)
        return np.array(resized_img).astype(np.float32)/255.0, mask, target_width, target_height

    elif method == 'inside':
        # Inside: å’Œ contain ç›¸åŒï¼Œä¿æŒå®½é«˜æ¯”ï¼Œç¼©å°æˆ–ä¸æ”¹å˜å›¾åƒä½¿å…¶å®Œå…¨é€‚åˆå®¹å™¨
        img_ratio = img_width / img_height
        target_ratio = target_width / target_height
        if img_ratio > target_ratio:
            new_width = target_width
            new_height = int(target_width / img_ratio)
        else:
            new_height = target_height
            new_width = int(target_height * img_ratio)
        resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # è§£æèƒŒæ™¯é¢œè‰²
        try:
            color = tuple(int(background_color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
        except ValueError:
            color = (0, 0, 0)  # é»˜è®¤é»‘è‰²
            
        padded_img = Image.new('RGB', (target_width, target_height), color)
        x_offset = (target_width - new_width) // 2
        y_offset = (target_height - new_height) // 2
        padded_img.paste(resized_img, (x_offset, y_offset))
        
        # ç”Ÿæˆmask
        mask = calculate_mask((img_width, img_height), (target_width, target_height), method, scale_factor=1.0)
        return np.array(padded_img).astype(np.float32)/255.0, mask, target_width, target_height

    elif method == 'outside':
        # Outside: å’Œ cover ç›¸åŒï¼Œä¿æŒå®½é«˜æ¯”ï¼Œæ”¾å¤§æˆ–ä¸æ”¹å˜å›¾åƒä½¿å…¶å®Œå…¨è¦†ç›–å®¹å™¨
        img_ratio = img_width / img_height
        target_ratio = target_width / target_height
        if img_ratio > target_ratio:
            new_height = target_height
            new_width = int(target_height * img_ratio)
        else:
            new_width = target_width
            new_height = int(target_width / img_ratio)
        resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        x_offset = (new_width - target_width) // 2
        y_offset = (new_height - target_height) // 2
        cropped_img = resized_img.crop((x_offset, y_offset, x_offset + target_width, y_offset + target_height))
        
        # ç”Ÿæˆmask
        mask = calculate_mask((img_width, img_height), (target_width, target_height), method, scale_factor=1.0)
        return np.array(cropped_img).astype(np.float32)/255.0, mask, target_width, target_height

def pad_image(image, target_width, target_height, position='center', background_color='#000000'):
    """Pad an image to the target dimensions with specified background color."""
    # å°†ComfyUIçš„å›¾åƒTensorè½¬æ¢ä¸ºPILå›¾åƒå¯¹è±¡
    img = Image.fromarray(np.clip(255. * image.cpu().numpy(), 0, 255).astype(np.uint8))
    img_width, img_height = img.size

    # è§£æåå…­è¿›åˆ¶é¢œè‰²
    try:
        color = tuple(int(background_color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
    except ValueError:
        print(f"Invalid color format: {background_color}, using black")
        color = (0, 0, 0)

    # åˆ›å»ºæŒ‡å®šé¢œè‰²çš„èƒŒæ™¯å›¾åƒ
    padded_img = Image.new('RGB', (target_width, target_height), color)

    # è®¡ç®—ç²˜è´´ä½ç½®
    if position == 'center':
        x_offset = (target_width - img_width) // 2
        y_offset = (target_height - img_height) // 2
    elif position == 'top':
        x_offset = (target_width - img_width) // 2
        y_offset = 0
    elif position == 'bottom':
        x_offset = (target_width - img_width) // 2
        y_offset = target_height - img_height
    elif position == 'left':
        x_offset = 0
        y_offset = (target_height - img_height) // 2
    elif position == 'right':
        x_offset = target_width - img_width
        y_offset = (target_height - img_height) // 2
    else:
        raise ValueError(f"Invalid pad position: {position}")

    # å°†åŸå›¾ç²˜è´´åˆ°èƒŒæ™¯ä¸Š
    padded_img.paste(img, (x_offset, y_offset))
    
    # ç”Ÿæˆmask
    mask = calculate_mask((img_width, img_height), (target_width, target_height), position, scale_factor=1.0)
    
    # è½¬æ¢å›ComfyUIéœ€è¦çš„æ ¼å¼
    return np.array(padded_img).astype(np.float32) / 255.0, mask, target_width, target_height

def calculate_resolution(aspect_ratio, scale_factor, max_width, max_height, min_width, min_height):
    """Calculate the target resolution based on aspect ratio and scale factor."""
    
    # SDXL æœ€ä½³åˆ†è¾¨ç‡å¯¹ç…§è¡¨
    base_resolutions = {
        "1:1": (1024, 1024),
        "9:7": (1152, 896),
        "7:9": (896, 1152),
        "3:2": (1216, 832),
        "2:3": (832, 1216),
        "7:4": (1344, 768),
        "4:7": (768, 1344),
        "12:5": (1536, 640),
        "5:12": (640, 1536),
    }
    
    # ä»è¾“å…¥ä¸­æå–æ¯”ä¾‹éƒ¨åˆ†
    ratio = aspect_ratio.split(" ")[0]
    
    # æŸ¥æ‰¾å¯¹åº”çš„åŸºç¡€åˆ†è¾¨ç‡
    if ratio in base_resolutions:
        base_width, base_height = base_resolutions[ratio]
    else:
        raise ValueError(f"Invalid aspect ratio: {ratio}")

    # è®¡ç®—åˆå§‹ç›®æ ‡å°ºå¯¸
    target_width = int(base_width * scale_factor)
    target_height = int(base_height * scale_factor)
    
    # åº”ç”¨æœ€å¤§åˆ†è¾¨ç‡çº¦æŸ
    current_max = max(target_width, target_height)
    if current_max > max_width or current_max > max_height:
        scale = min(max_width / current_max, max_height / current_max)
        target_width = int(target_width * scale)
        target_height = int(target_height * scale)
    
    # åº”ç”¨æœ€å°åˆ†è¾¨ç‡çº¦æŸ
    current_min = min(target_width, target_height)
    if current_min < min_width or current_min < min_height:
        scale = max(min_width / current_min, min_height / current_min)
        target_width = int(target_width * scale)
        target_height = int(target_height * scale)
    
    return target_width, target_height, base_width, base_height

def get_aspect_ratio_string(width, height):
    """Get the aspect ratio string from width and height, maintaining standard ratios"""
    # SDXL æ ‡å‡†æ¯”ä¾‹æ˜ å°„
    sdxl_ratios = {
        (1024, 1024): "1:1",
        (1152, 896): "9:7",
        (896, 1152): "7:9",
        (1216, 832): "3:2",
        (832, 1216): "2:3",
        (1344, 768): "7:4",
        (768, 1344): "4:7",
        (1536, 640): "12:5",
        (640, 1536): "5:12"
    }
    
    # Midjourney æ ‡å‡†æ¯”ä¾‹æ˜ å°„
    midjourney_ratios = {
        (1024, 1024): "1:1",
        (1200, 992): "6:5",
        (1232, 928): "4:3",
        (1344, 896): "3:2",
        (1456, 816): "16:9",
        (1536, 768): "2:1",
        (768, 1536): "1:2",
        (816, 1456): "9:16",
        (896, 1344): "2:3",
        (928, 1232): "3:4",
        (992, 1200): "5:6"
    }
    
    # åˆå¹¶æ‰€æœ‰æ ‡å‡†æ¯”ä¾‹
    standard_ratios = {**sdxl_ratios, **midjourney_ratios}
    
    # å¦‚æœæ˜¯æ ‡å‡†åˆ†è¾¨ç‡ï¼Œç›´æ¥è¿”å›å¯¹åº”çš„æ¯”ä¾‹
    if (width, height) in standard_ratios:
        return standard_ratios[(width, height)]
    
    # å¦‚æœä¸æ˜¯æ ‡å‡†åˆ†è¾¨ç‡ï¼Œåˆ™ä½¿ç”¨æœ€å¤§å…¬çº¦æ•°è®¡ç®—
    common_divisor = gcd(width, height)
    aspect_width = width // common_divisor
    aspect_height = height // common_divisor
    return f"{aspect_width}:{aspect_height}"

def create_outline(image, background_color):
    """ç»™å›¾ç‰‡æ·»åŠ 1åƒç´ çš„æè¾¹ï¼Œä½¿ç”¨èƒŒæ™¯è‰²çš„åè‰²"""
    # å°†èƒŒæ™¯è‰²è½¬æ¢ä¸ºRGBå…ƒç»„
    try:
        bg_color = tuple(int(background_color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
    except ValueError:
        bg_color = (0, 0, 0)
    
    # è®¡ç®—åè‰²
    outline_color = tuple(255 - c for c in bg_color)
    
    # å°†å›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
    img = Image.fromarray(np.clip(255. * image, 0, 255).astype(np.uint8))
    width, height = img.size
    
    # åˆ›å»ºæ–°å›¾åƒï¼Œæ¯”åŸå›¾å¤§2åƒç´ 
    outlined = Image.new('RGB', (width + 2, height + 2), outline_color)
    # å°†åŸå›¾ç²˜è´´åˆ°ä¸­å¿ƒ
    outlined.paste(img, (1, 1))
    
    # è½¬æ¢å›tensoræ ¼å¼
    return np.array(outlined).astype(np.float32) / 255.0

def calculate_mask(original_size, target_size, extend_mode, feather=0, scale_factor=1.0):
    """è®¡ç®—å¡«å……åŒºåŸŸçš„maskï¼Œåªåœ¨æœ‰èƒŒæ™¯åŒºåŸŸæ—¶æ·»åŠ ç¾½åŒ–æ•ˆæœ"""
    orig_w, orig_h = original_size
    target_w, target_h = target_size
    
    # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„maskï¼ˆé»˜è®¤å…¨ç™½ï¼Œè¡¨ç¤ºèƒŒæ™¯ï¼‰
    mask = torch.ones((target_h, target_w))
    
    if extend_mode in ["top", "bottom", "left", "right", "center"]:
        # è¿™äº›æ¨¡å¼ä¸‹åŸå§‹å›¾åƒå°ºå¯¸ä¸å˜ï¼Œåªæœ‰ç›®æ ‡å°ºå¯¸å—scale_factorå½±å“
        new_w = orig_w  # ä¸å¯¹åŸå§‹å°ºå¯¸åº”ç”¨scale_factor
        new_h = orig_h

        if extend_mode == "center":
            x_offset = max(0, (target_w - new_w) // 2)
            y_offset = max(0, (target_h - new_h) // 2)
        elif extend_mode == "top":
            x_offset = max(0, (target_w - new_w) // 2)
            y_offset = 0
        elif extend_mode == "bottom":
            x_offset = max(0, (target_w - new_w) // 2)
            y_offset = max(0, target_h - new_h)
        elif extend_mode == "left":
            x_offset = 0
            y_offset = max(0, (target_h - new_h) // 2)
        else:  # right
            x_offset = max(0, target_w - new_w)
            y_offset = max(0, (target_h - new_h) // 2)

        actual_w = min(new_w, target_w - x_offset)
        actual_h = min(new_h, target_h - y_offset)

        if actual_w > 0 and actual_h > 0:
            content_area = torch.zeros((actual_h, actual_w))
            mask[y_offset:y_offset + actual_h, x_offset:x_offset + actual_w] = content_area
            
            if feather > 0:
                scaled_feather = int(feather * scale_factor)
                
                # åˆ¤æ–­å“ªäº›è¾¹éœ€è¦ç¾½åŒ–
                has_top = y_offset > 0
                has_bottom = y_offset + actual_h < target_h
                has_left = x_offset > 0
                has_right = x_offset + actual_w < target_w
                
                for i in range(target_h):
                    for j in range(target_w):
                        if i < y_offset or i >= y_offset + actual_h or j < x_offset or j >= x_offset + actual_w:
                            continue
                            
                        # åªè®¡ç®—éœ€è¦ç¾½åŒ–çš„è¾¹çš„è·ç¦»
                        dt = i - y_offset if has_top and i - y_offset < scaled_feather else scaled_feather
                        db = (y_offset + actual_h - i - 1) if has_bottom and (y_offset + actual_h - i - 1) < scaled_feather else scaled_feather
                        dl = j - x_offset if has_left and j - x_offset < scaled_feather else scaled_feather
                        dr = (x_offset + actual_w - j - 1) if has_right and (x_offset + actual_w - j - 1) < scaled_feather else scaled_feather
                        
                        d = min(dt, db, dl, dr)
                        if d < scaled_feather:
                            v = 1.0 - (d / scaled_feather)
                            mask[i, j] = v * v
    
    elif extend_mode == "fill":
        mask.fill_(0.0)
        
    elif extend_mode in ["cover", "outside"]:
        mask.fill_(0.0)
        
    elif extend_mode in ["contain", "inside"]:
        ratio = min(target_w/orig_w, target_h/orig_h)
        new_w = int(orig_w * ratio)
        new_h = int(orig_h * ratio)
        
        x_offset = (target_w - new_w) // 2
        y_offset = (target_h - new_h) // 2
        
        # åˆ›å»ºåŸºç¡€mask
        base_mask = torch.zeros((new_h, new_w))
        
        # åªåœ¨æœ‰èƒŒæ™¯åŒºåŸŸæ—¶æ·»åŠ ç¾½åŒ–æ•ˆæœ
        if feather > 0 and (x_offset > 0 or y_offset > 0):
            for i in range(new_h):
                for j in range(new_w):
                    # åªåœ¨è¾¹ç¼˜æœ‰èƒŒæ™¯æ—¶è®¡ç®—ç¾½åŒ–
                    dt = i if y_offset > 0 else new_h
                    db = new_h - i - 1 if y_offset > 0 else new_h
                    dl = j if x_offset > 0 else new_w
                    dr = new_w - j - 1 if x_offset > 0 else new_w
                    
                    d = min(dt, db, dl, dr)
                    
                    if d >= feather:
                        continue
                        
                    v = (feather - d) / feather
                    base_mask[i, j] = v * v
        
        mask[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = base_mask

    return mask

class ImageResolutionAdjuster:
    def __init__(self):
        self.selected_color = "#000000"
    
    @classmethod
    def get_resolution_options(cls):
        """Generate resolution options for SDXL and Midjourney optimal resolutions"""
        # SDXLåŸºç¡€åˆ†è¾¨ç‡
        sdxl_resolutions = [
            (1024, 1024),  # 1:1
            (1152, 896),   # 9:7
            (896, 1152),   # 7:9
            (1216, 832),   # 3:2
            (832, 1216),   # 2:3
            (1344, 768),   # 7:4
            (768, 1344),   # 4:7
            (1536, 640),   # 12:5
            (640, 1536),   # 5:12
        ]
        
        # MidjourneyåŸºç¡€åˆ†è¾¨ç‡
        midjourney_resolutions = [
            (1024, 1024),  # 1:1
            (1200, 992),   # 6:5
            (1232, 928),   # 4:3
            (1344, 896),   # 3:2
            (1456, 816),   # 16:9
            (1536, 768),   # 2:1
            (768, 1536),   # 1:2
            (816, 1456),   # 9:16
            (896, 1344),   # 2:3
            (928, 1232),   # 3:4
            (992, 1200),   # 5:6
        ]
        
        # åˆå¹¶æ‰€æœ‰åˆ†è¾¨ç‡å¹¶å»é‡
        all_resolutions = list(set(sdxl_resolutions + midjourney_resolutions))
        
        # åˆ›å»ºå¸¦æœ‰æ¯”ä¾‹å€¼çš„å…ƒç»„åˆ—è¡¨
        resolution_ratios = []
        for width, height in all_resolutions:
            ratio = width / height  # è®¡ç®—å®é™…æ¯”ä¾‹å€¼
            ratio_str = get_aspect_ratio_string(width, height)
            resolution_ratios.append((ratio, f"{ratio_str} ({width}x{height})"))
        
        # æŒ‰æ¯”ä¾‹å€¼æ’åºï¼ˆä»å°åˆ°å¤§ï¼‰
        resolution_ratios.sort(key=lambda x: x[0])
        
        # åªè¿”å›åˆ†è¾¨ç‡å­—ç¬¦ä¸²
        return [item[1] for item in resolution_ratios]

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "images": ("IMAGE",),
                "target_resolution": (s.get_resolution_options(),),
                "extend_mode": (["contain", "cover", "fill", "inside", "outside", "top", "bottom", "left", "right", "center"],),
                "scale_factor": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.1}),
                "max_width": ("INT", {"default": 2048, "min": 1, "max": 8192, "step": 1}),
                "max_height": ("INT", {"default": 2048, "min": 1, "max": 8192, "step": 1}),
                "min_width": ("INT", {"default": 640, "min": 1, "max": 8192, "step": 1}),
                "min_height": ("INT", {"default": 640, "min": 1, "max": 8192, "step": 1}),
                "background_color": ("STRING", {"default": "#000000", "multiline": False}),
                "feathering": ("INT", {"default": 40, "min": 0, "max": 512, "step": 1}),
                "invert_mask": ("BOOLEAN", {"default": False}),
                "add_outline": ("BOOLEAN", {"default": False}),
            },
            "hidden": {"color_widget": "COMBO"}
        }

    CATEGORY = "ğŸ¨PaintingğŸ‘“Coder/ğŸ–¼ï¸Image"
    RETURN_TYPES = ("IMAGE", "MASK", "INT", "INT")
    RETURN_NAMES = ("images", "mask", "width", "height")
    FUNCTION = "adjust_resolution"

    def adjust_resolution(self, images, target_resolution, extend_mode, background_color, scale_factor, max_width, max_height, min_width, min_height, invert_mask, add_outline, feathering=40):
        output_images = []
        output_masks = []
        
        # ä»ç›®æ ‡åˆ†è¾¨ç‡å­—ç¬¦ä¸²ä¸­æå–å®½é«˜æ¯”å’Œå°ºå¯¸
        import re
        match = re.search(r'(\d+:\d+)\s*\((\d+)x(\d+)\)', target_resolution)
        if not match:
            raise ValueError(f"Invalid resolution format: {target_resolution}")
        
        aspect_ratio = match.group(1)
        base_width = int(match.group(2))
        base_height = int(match.group(3))
        
        # è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡
        target_width = int(base_width * scale_factor)
        target_height = int(base_height * scale_factor)
        
        # åº”ç”¨æœ€å¤§åˆ†è¾¨ç‡çº¦æŸ
        current_max = max(target_width, target_height)
        if current_max > max_width or current_max > max_height:
            scale = min(max_width / current_max, max_height / current_max)
            target_width = int(target_width * scale)
            target_height = int(target_height * scale)
        
        # åº”ç”¨æœ€å°åˆ†è¾¨ç‡çº¦æŸ
        current_min = min(target_width, target_height)
        if current_min < min_width or current_min < min_height:
            scale = max(min_width / current_min, min_height / current_min)
            target_width = int(target_width * scale)
            target_height = int(target_height * scale)
        
        # ç¡®ä¿å°ºå¯¸ä¸º8çš„å€æ•°
        target_width = (target_width // 8) * 8
        target_height = (target_height // 8) * 8
        
        for image in images:
            if extend_mode in ["contain", "cover", "fill", "inside", "outside"]:
                scaled_image, mask, width, height = resize_image(image, target_width, target_height, method=extend_mode, background_color=background_color)
                mask = calculate_mask((image.shape[1], image.shape[0]), (width, height), extend_mode, feather=feathering, scale_factor=scale_factor)
            elif extend_mode in ["top", "bottom", "left", "right", "center"]:
                scaled_image, mask, width, height = pad_image(image, target_width, target_height, 
                                                      position=extend_mode, 
                                                      background_color=background_color)
                mask = calculate_mask((image.shape[1], image.shape[0]), (width, height), extend_mode, feather=feathering, scale_factor=scale_factor)
            else:
                raise ValueError(f"Invalid extend_mode: {extend_mode}")
            
            if add_outline:
                scaled_image = create_outline(scaled_image, background_color)
                mask = F.pad(mask, (1, 1, 1, 1), mode='constant', value=0)
                width += 2
                height += 2
            
            output_images.append(torch.from_numpy(scaled_image).unsqueeze(0))
            output_masks.append(mask.unsqueeze(0))
        
        output_images = torch.cat(output_images, dim=0)
        output_masks = torch.cat(output_masks, dim=0)
        
        if invert_mask:
            output_masks = 1.0 - output_masks
        
        return (output_images, output_masks, width, height)

    @classmethod
    def VALIDATE_INPUTS(s, **kwargs):
        if "background_color" in kwargs:
            color = kwargs["background_color"]
            # éªŒè¯é¢œè‰²æ ¼å¼
            if not color.startswith('#') or len(color) != 7:
                return False
            try:
                # å°è¯•è§£æåå…­è¿›åˆ¶é¢œè‰²
                int(color[1:], 16)
            except ValueError:
                return False
        return True

    # æ·»åŠ  Widget å®šä¹‰
    @classmethod
    def WIDGETS(s):
        return {"color_widget": {"widget_type": "color_picker", "target": "background_color"}}

# æ›´æ–°èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "PaintingCoder::ImageResolutionAdjuster": ImageResolutionAdjuster,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "PaintingCoder::ImageResolutionAdjuster": "Image Resolution Adjuster ğŸ“",
}
